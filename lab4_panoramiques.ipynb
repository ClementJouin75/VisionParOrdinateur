{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4 - Création de panoramiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Presser une touche pour continuer & esc pour arreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de correspondances : 3247\n",
      "Nombre de meilleures correspondances : 10\n",
      "Meilleure correspondance 1 : Distance = 6.0\n",
      "Meilleure correspondance 2 : Distance = 10.0\n",
      "Meilleure correspondance 3 : Distance = 10.0\n",
      "Meilleure correspondance 4 : Distance = 10.0\n",
      "Meilleure correspondance 5 : Distance = 11.0\n",
      "Meilleure correspondance 6 : Distance = 11.0\n",
      "Meilleure correspondance 7 : Distance = 11.0\n",
      "Meilleure correspondance 8 : Distance = 11.0\n",
      "Meilleure correspondance 9 : Distance = 11.0\n",
      "Meilleure correspondance 10 : Distance = 12.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ESC_KEY = 27\n",
    "\n",
    "class MyFeatureDetector:\n",
    "    @staticmethod\n",
    "    def createORB():\n",
    "        return cv2.ORB_create(10000)  # Paramètre ajustable: Nombre maximum de points-clés à détecter\n",
    "\n",
    "class MyDescriptorExtractor:\n",
    "    @staticmethod\n",
    "    def createORB():\n",
    "        return cv2.ORB_create(10000)  # Paramètre ajustable: Nombre maximum de points-clés à détecter\n",
    "\n",
    "class MyImageProcessor:\n",
    "    def __init__(self, image_path):\n",
    "        self._myImage = cv2.imread(image_path)\n",
    "        if self._myImage is None or self._myImage.size == 0 or self._myImage.shape[0] == 0 or self._myImage.shape[1] == 0:\n",
    "            print(f\"Ne parvient pas à ouvrir {image_path}\")\n",
    "            exit(1)\n",
    "\n",
    "    def displayImage(self, window_name):\n",
    "        cv2.namedWindow(window_name)\n",
    "        cv2.imshow(window_name, self._myImage)\n",
    "\n",
    "    def displayKeypoints(self, keypoints, rgb=(0, 0, 255)):\n",
    "        if keypoints:\n",
    "            img_with_keypoints = cv2.drawKeypoints(self._myImage, keypoints, None, color=rgb)\n",
    "            cv2.imshow(\"Image avec points clés\", img_with_keypoints)\n",
    "            return img_with_keypoints\n",
    "\n",
    "def main():\n",
    "    # Charger les images\n",
    "    image_processor1 = MyImageProcessor(\"img/IMG_3_reduced.jpg\")\n",
    "    image_processor2 = MyImageProcessor(\"img/IMG_4_reduced.jpg\")\n",
    "\n",
    "    # Afficher les images\n",
    "    image_processor1.displayImage(\"Image 1\")\n",
    "    image_processor2.displayImage(\"Image 2\")\n",
    "\n",
    "    # Détection et calcul des caractéristiques pour l'image 1\n",
    "    feature_detector = MyFeatureDetector.createORB()\n",
    "    keypoints1, descriptors1 = feature_detector.detectAndCompute(image_processor1._myImage, None)\n",
    "    image_processor1.displayKeypoints(keypoints1)\n",
    "\n",
    "    # Attendre une touche pour continuer\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Détection et calcul des caractéristiques pour l'image 2\n",
    "    keypoints2, descriptors2 = feature_detector.detectAndCompute(image_processor2._myImage, None)\n",
    "    image_processor2.displayKeypoints(keypoints2)\n",
    "\n",
    "    # Attendre une touche pour continuer\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Correspondance des descripteurs entre les deux images\n",
    "    descriptor_extractor = MyDescriptorExtractor.createORB()\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Afficher le nombre total de correspondances\n",
    "    print(f\"Nombre total de correspondances : {len(matches)}\")\n",
    "\n",
    "    # Afficher le nombre de meilleures correspondances\n",
    "    num_best_matches = 10  # Paramètre ajustable: Nombre de meilleures correspondances à afficher\n",
    "    print(f\"Nombre de meilleures correspondances : {num_best_matches}\")\n",
    "\n",
    "    # Afficher les meilleures correspondances\n",
    "    for i in range(num_best_matches):\n",
    "        print(f\"Meilleure correspondance {i + 1} : Distance = {matches[i].distance}\")\n",
    "\n",
    "    # Afficher le matching entre les points des images 1 et 2\n",
    "    match_img = cv2.drawMatches(image_processor1._myImage, keypoints1, image_processor2._myImage, keypoints2, matches[:num_best_matches], None)\n",
    "    cv2.imshow(\"Matching\", match_img)\n",
    "\n",
    "    # Calculer l'homographie\n",
    "    im1Pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    im2Pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    homography, _ = cv2.findHomography(im2Pts, im1Pts, cv2.RANSAC, 1.5)\n",
    "\n",
    "    if homography is not None:\n",
    "        # Appliquer l'homographie\n",
    "        result = cv2.warpPerspective(image_processor2._myImage, homography, (image_processor1._myImage.shape[1] + image_processor2._myImage.shape[1], image_processor2._myImage.shape[0]))\n",
    "\n",
    "        # Ajouter l'image de gauche\n",
    "        result[0:image_processor1._myImage.shape[0], 0:image_processor1._myImage.shape[1]] = image_processor1._myImage\n",
    "\n",
    "        cv2.imshow(\"Warping\", result)\n",
    "\n",
    "    # Lancer la boucle infinie\n",
    "    retK = 0\n",
    "    while retK != ESC_KEY:\n",
    "        # Attendre une pression de touche\n",
    "        retK = cv2.waitKey(1)\n",
    "\n",
    "    # Fin du programme\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Appeler la fonction principale\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1 avec points d'interets](./img/IMG_3_reduced.jpg) ![img1 avec points d'interets](./captures/img.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1 avec points d'interets](./img/IMG_4_reduced.jpg) ![img1 avec points d'interets](./captures/img3.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1 avec points d'interets](./captures/img4.png) ![img1 avec points d'interets](./captures/img5.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
